@startuml pytorch-tracing

title __**Potential PyTorch Tracing Interface**__

!$user = "User"
!$python = "./bindings/python"
!$torch = "torch"
!$ffi = "./lib/ffi"
!$pcg = "./lib/pcg"
!$runtime = "./lib/runtime"
!$compiler = "./lib/compiler"
!$runtimeBacking = "RuntimeBacking"
!$legion = "legion"
!$participantBGColor = "#FFFFFF"

skinparam defaultFontName Courier
skinparam defaultFontStyle bold
skinparam arrowFontStyle bold
skinparam responseMessageBelowArrow true
skinparam sequenceMessageAlign left
skinparam sequenceReferenceAlign left
skinparam sequenceReferenceFontStyle bold
skinparam participantBackgroundColor #F0F0F0

participant U as "$user"
participant P as "$python"
participant T as "$torch"
participant F as "$ffi"
participant G as "$pcg"
participant R as "$runtime"
participant C as "$compiler"
participant B as "$runtimeBacking"
participant L as "$legion"

!function $get_idx($participant)
  !if ($participant == "$user")
    !return 0
  !elseif ($participant == "$python")
    !return 1
  !elseif ($participant == "$torch")
    !return 2
  !elseif ($participant == "$ffi")
    !return 3
  !elseif ($participant == "$pcg")
    !return 4
  !elseif ($participant == "$runtime")
    !return 5
  !elseif ($participant == "$compiler")
    !return 6
  !elseif ($participant == "$runtimeBacking")
    !return 7
  !elseif ($participant == "$legion")
    !return 8
  !endif
!endfunction

!procedure $remind_participants($start="$user", $end="$legion")
  |||
  !$start_idx = $get_idx($start)
  !$end_idx = $get_idx($end) + 1
  !log start_idx is $start_idx, end_idx is $end_idx
  !if ($start_idx <= 0 && $end_idx > 0)
    !log User
    rnote over U $participantBGColor: $user
  !endif
  !if ($start_idx <= 1 && $end_idx > 1)
    /rnote over P $participantBGColor: $python
  !endif
  !if ($start_idx <= 2 && $end_idx > 2)
    /rnote over T $participantBGColor: $torch
  !endif
  !if ($start_idx <= 3 && $end_idx > 3)
    /rnote over F $participantBGColor: $ffi
  !endif
  !if ($start_idx <= 4 && $end_idx > 4)
    /rnote over G $participantBGColor: $pcg
  !endif
  !if ($start_idx <= 5 && $end_idx > 5)
    /rnote over R $participantBGColor: $runtime
  !endif
  !if ($start_idx <= 6 && $end_idx > 6)
    /rnote over C $participantBGColor: $compiler
  !endif
  !if ($start_idx <= 7 && $end_idx > 7)
    /rnote over B $participantBGColor: $runtimeBacking
  !endif
  !if ($start_idx <= 8 && $end_idx > 8)
    !log Legion
    /rnote over L $participantBGColor: $legion
  !endif
  |||
!endprocedure

U->>P:\
import flexflow.torch as torch\l\
import flexflow.torch.nn as nn\l\
\l\
~# borrowed from [[https://pytorch.org/tutorials/beginner/basics/optimization_tutorial.html the pytorch tutorial]]\l\
class NeuralNetwork(nn.Module):\l\
  def ~__init__(self):\l\
    super(NeuralNetwork, self).~__init__()\l\
    self.flatten = nn.Flatten()\l\
    self.linear_relu_stack = nn.Sequential(\l\
      nn.Linear(28*28, 512),\l\
      nn.ReLU(),\l\
      nn.Linear(512, 512),\l\
      nn.ReLU(),\l\
      nn.Linear(512, 10),\l\
    )\l\
    \l\
    def forward(self, x):\l\
      x = self.flatten(x)\l\
      logits = self.linear_relu_stack(x)\l\
      return logits\l\
\l\
def top_level_task():\l\
  model = NeuralNetwork()

$remind_participants()

alt fx
U->>P:\l\
  compiled_model = model.compile(\l\
    algorithm=...,\l\
    optimizer=...\l\
  )

  P->>T:\
from torch.fx import symbolic_trace\l\
\l\
symbolic_traced  = symbolic_trace(model)\l\

  T->>T:\
  model.forward(<tracing tensor>)

  T->>P:\
symbolic_traced : torch.fx.GraphModule

  ref over P 
    compiled_model = compilation(symbolic_traced) # see below 
  end

  P->>U:\
    compiled_model: CompiledModel
else dynamo
  U->>T:\l\
  compiled_model = torch.compile(\l\
    model,\l\
    backend='flexflow',\l\
    options=dict(\l\
      algorithm=...,\l\
      optimizer=...\l\
    )\l\
  )

  T->>P:\
def flexflow_compiler(\l\
  gm: torch.fx.GraphModule,\l\
  example_inputs: List[torch.Tensor])\l\
    -> CompiledModel

  ref over P 
    compiled_model = compilation(gm) # see below 
  end

  P->>T: compiled_model: CompiledModel

  T->>U:\
  compiled_model: CompiledModel

end

$remind_participants()

group compilation [def compilation(g: torch.fx.GraphModule) -> CompiledModel]

    ?-->P: g: torch.fx.GraphModule

    P->>P:\
  ff_model = flexflow.torch.from_fx(symbolic_traced)

    group flexflow.torch.from_fx [def from_fx(g: torch.fx.GraphModule) -> ComputationGraph]
      $remind_participants("$python", "$pcg")

      ?-->P: g: torch.fx.GraphModule

      P->>F: flexflow_computation_graph_create(...)
    
      |||

      F->>P:\
    typedef struct {\l\
      ComputationGraphBuilder *ptr;\l\
    } flexflow_computation_graph_builder_t;

      |||

      P->>F: flexflow_computation_graph_add_op_flat(...)

      F->>G:\
    ComputationGraphBuilder::flat(...);

      |||

      G->>F:\
    struct Tensor { ... };

      F->>P:\
    typedef struct {\l\
      Tensor *ptr;\l\
    } flexflow_tensor_t;


      P->>F: flexflow_computation_graph_add_op_dense(...)

      F->>G:\
    ComputationGraphBuilder::dense(...);

      |||

      G->>F: Tensor

      F->>P: flexflow_tensor_t

      |||

      P->>F: flexflow_computation_graph_add_op_relu(...)

      F->>G:\
    ComputationGraphbuilder::relu(...);

      |||

      G->>F: Tensor

      F->>P: flexflow_tensor_t

      note over P, G
        ..., etc.
      end note

      ?<--P: comp_graph\l : ComputationGraph
    end

    |||

  group optimization [def optimization(comp_graph: ComputationGraph) -> CompiledModel]

  $remind_participants("$python", "$compiler")

  ?-->P: comp_graph\l : ComputationGraph

  P->>F:\l\
  flexflow_error_t\l\
  flexflow_computation_graph_compile(\l\
    flexflow_computation_graph_t,\l\
    flexflow_optimizer_t,\l\
    flexflow_compilation_algorithm_t,\l\
    flexflow_model_compilation_result *out\l\
  );

  F->>R:\
  ModelCompilationResult optimize(\l\
    ComputationGraph const &,\l\
    AlgorithmConfig const &\l\
  );

  R->>C:\
  SearchResult optimize(\l\
    ComputationGraph const &,\l\
    MachineSpecification const &,\l\
    CostEstimator const &,\l\
    AlgorithmConfig const &\l\
  );

  |||

  C->>R:\
  struct SearchResult {\l\
    ParallelComputationGraph pcg;\l\
    TensorMapping tensor_mapping;\l\
    SearchSolution solution;\l\
    CostValues cost_values;\l\
  };

  R->>F:\
  struct ModelCompilationResult {\l\
    ComputationGraph computation_graph;\l\
    ParallelComputationGraph pcg;\l\
    TensorMapping tensor_mapping;\l\
  };

  F->>P:\
  typedef struct {\l\
    ModelCompilationResult *ptr;\l\
  } model_compilation_result_t;

  |||

  ?<--P: compiled_model\l : CompiledModel
end

?<--P: compiled_model : CompiledModel

end


$remind_participants()


group serialization

  

end

loop 

  group fwd

    U->>P:\
pred = compiled_model(batch)

    opt if first iteration
      P->>F:\
flexflow_error_t\l\
flexflow_start_training(\l\
  flexflow_model_compilation_result_t,\l\
  flexflow_model_compilation_result_t *out\l\
);

      |||

      F->>P:\
typedef struct {\l\
  ModelTrainingInstance *ptr;\l\
} flexflow_model_training_instance_t;

      |||

      P->>P: model.training_instance = ...
    end

    P->>U:\
pred: TensorFuture

    |||

    U->>P:\
loss = loss_fn(pred, label)

    P->>F:\
flexflow_error_t\l\
flexflow_model_training_instance_forward(\l\
  flexflow_model_training_instance_t\l\
);

    F->>R:\
forward(ModelTrainingInstance const &);

    loop
      R->>B:\
    execute(OpTaskInvocation const &);

      B->>L:\
IndexLauncher launcher;\l\
...\l\
runtime->execute_index_space(ctx, launcher);\l\
    end
  end

    R->>F:

    F->>P:

    P->>U:\
loss: LossTensor

  end

  group bwd

  U->>P:\
loss.backward()

  P->>F:\
flexflow_error_t\l\
flexflow_model_training_instance_backward(\l\
  flexflow_model_training_instance_t\l\
);

  F->>R:\

  R->>B:

  B->>R:

  R->>F:

  F->>P:

  end

  group update

  U->>P:\
optimizer.step()

  P->>F:\
flexflow_error_t\l\
flexflow_model_training_instance_update(\l\
  flexflow_model_training_instance_t\l\
);

  F->>R:

  R->>B:

  B->>R:

  R->>F:

  F->>P:

  end
end

P->>F:\
flexflow_error_t\l\
flexflow_stop_training(\l\
  flexflow_model_training_instance_t\l\
);


opt Reading tensor elements
    U->>P: get_tensor
    P->>F:
    F->>R:
    R->>B:
    R->>F:
    F->>P:
    P->>U:
end
opt Writing to tensor elements
    U->>P: set_tensor
    P->>F:
    F->>R: 
    R->>B:
    B->>R:
    R->>F:
    F->>P:
    P->>U:
end

@enduml
